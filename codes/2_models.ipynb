{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "- [Import libraries](#import_libraries)\n",
    "- [Load processed dataset](#load_dataset)\n",
    "- [Split data into features and labels](#split_data)\n",
    "- [Baseline algorithms](#baseline_algorithms)\n",
    "- [Grid search and hyper-parameter tuning](#grid_search)\n",
    "    - [Logistic regression](#grid_logistic1)\n",
    "    - [XGBoost classifier](#grid_xgboost1)\n",
    "- [Synthetic Minority Oversampling (SMOTE)]\n",
    "- [Feature selection using Recursive Feature Elimination](#rfe)\n",
    "    - [Baseline algorithms]\n",
    "    - [Grid search and hyper-parameter tuning]\n",
    "    - [Synthetic Minority Oversampling (SMOTE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries <a name=\"import_libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "from sklearn.metrics import roc_auc_score, classification_report, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed dataset <a name=\"load_dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "      <th>...</th>\n",
       "      <th>education_high.school</th>\n",
       "      <th>education_illiterate</th>\n",
       "      <th>education_professional.course</th>\n",
       "      <th>education_university.degree</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.146223</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387151</td>\n",
       "      <td>0.845340</td>\n",
       "      <td>0.599402</td>\n",
       "      <td>-0.490205</td>\n",
       "      <td>0.772003</td>\n",
       "      <td>0.865709</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.076166</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2.147042</td>\n",
       "      <td>0.845340</td>\n",
       "      <td>1.602685</td>\n",
       "      <td>-0.275213</td>\n",
       "      <td>0.716988</td>\n",
       "      <td>0.865709</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.146223</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.973782</td>\n",
       "      <td>0.845340</td>\n",
       "      <td>-0.269988</td>\n",
       "      <td>1.086402</td>\n",
       "      <td>0.774320</td>\n",
       "      <td>0.865709</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.511255</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.786110</td>\n",
       "      <td>0.650722</td>\n",
       "      <td>0.738797</td>\n",
       "      <td>1.014738</td>\n",
       "      <td>0.714672</td>\n",
       "      <td>0.326483</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017885</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.786110</td>\n",
       "      <td>-1.230581</td>\n",
       "      <td>-1.280608</td>\n",
       "      <td>-1.326284</td>\n",
       "      <td>-1.352159</td>\n",
       "      <td>-1.009227</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  month  day_of_week  campaign  emp.var.rate  cons.price.idx  \\\n",
       "0 -1.146223      7            5  0.387151      0.845340        0.599402   \n",
       "1  1.076166      6            3  2.147042      0.845340        1.602685   \n",
       "2 -1.146223      8            2  0.973782      0.845340       -0.269988   \n",
       "3 -0.511255      5            4 -0.786110      0.650722        0.738797   \n",
       "4  0.017885      5            2 -0.786110     -1.230581       -1.280608   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  y  ...  education_high.school  \\\n",
       "0      -0.490205   0.772003     0.865709 -1  ...                      0   \n",
       "1      -0.275213   0.716988     0.865709 -1  ...                      0   \n",
       "2       1.086402   0.774320     0.865709 -1  ...                      0   \n",
       "3       1.014738   0.714672     0.326483 -1  ...                      0   \n",
       "4      -1.326284  -1.352159    -1.009227 -1  ...                      1   \n",
       "\n",
       "   education_illiterate  education_professional.course  \\\n",
       "0                     0                              0   \n",
       "1                     0                              0   \n",
       "2                     0                              0   \n",
       "3                     0                              0   \n",
       "4                     0                              0   \n",
       "\n",
       "   education_university.degree  default_yes  housing_yes  loan_yes  \\\n",
       "0                            0            0            1         1   \n",
       "1                            1            0            0         0   \n",
       "2                            1            0            0         0   \n",
       "3                            1            0            0         0   \n",
       "4                            0            0            0         0   \n",
       "\n",
       "   contact_telephone  poutcome_nonexistent  poutcome_success  \n",
       "0                  1                     1                 0  \n",
       "1                  1                     1                 0  \n",
       "2                  0                     1                 0  \n",
       "3                  1                     1                 0  \n",
       "4                  0                     1                 0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/'\n",
    "train = pd.read_csv(path+'processed-train.csv',delimiter=',')\n",
    "test = pd.read_csv(path+'processed-test.csv',delimiter=',')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into features and labels <a name=\"split_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors\n",
    "x_train = train.drop(['y'], 1)\n",
    "x_test = test.drop(['y'], 1)\n",
    "\n",
    "# Target values\n",
    "y_train = train['y']\n",
    "y_test = test['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline algorithms <a name=\"baseline_algorithms\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run some baseline algorithms with default hyper-parameters on the training data to see how they perform. We will consider the following algorithms: **Logistic regression**, **Decision tree**, **Random forest**, **Gradient boosting classifier** and **k-Nearest neighbor**. For each algorithm, we will perform 5-fold cross-validation on the training set and store the mean classification accuracy and mean AUC-ROC (Area under ROC curve) along with the standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of algorithms to implement\n",
    "models = []\n",
    "models.append(('Logistic regression', LogisticRegression(max_iter=500)))\n",
    "models.append(('k-Nearest neighbor', KNeighborsClassifier()))\n",
    "models.append(('Decision tree', DecisionTreeClassifier()))\n",
    "models.append(('Random forest', RandomForestClassifier()))\n",
    "models.append(('XGBoost classifier', XGBClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean ROC-AUC</th>\n",
       "      <th>S.D. AUC-ROC</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>S.D. Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient boosting classifier</td>\n",
       "      <td>0.799690</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>0.901548</td>\n",
       "      <td>0.003802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.780577</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>0.901214</td>\n",
       "      <td>0.003305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost classifier</td>\n",
       "      <td>0.776692</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>0.895446</td>\n",
       "      <td>0.004962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.773770</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.892623</td>\n",
       "      <td>0.003945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k-Nearest neighbor</td>\n",
       "      <td>0.723551</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.889951</td>\n",
       "      <td>0.002840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.624478</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>0.840255</td>\n",
       "      <td>0.002616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Algorithm  Mean ROC-AUC  S.D. AUC-ROC  Mean Accuracy  \\\n",
       "4  Gradient boosting classifier      0.799690      0.006566       0.901548   \n",
       "0           Logistic regression      0.780577      0.009218       0.901214   \n",
       "5            XGBoost classifier      0.776692      0.011932       0.895446   \n",
       "3                 Random forest      0.773770      0.004436       0.892623   \n",
       "1            k-Nearest neighbor      0.723551      0.009259       0.889951   \n",
       "2                 Decision tree      0.624478      0.010074       0.840255   \n",
       "\n",
       "   S.D. Accuracy  \n",
       "4       0.003802  \n",
       "0       0.003305  \n",
       "5       0.004962  \n",
       "3       0.003945  \n",
       "1       0.002840  \n",
       "2       0.002616  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe to store classification metrics\n",
    "col = ['Algorithm', 'Mean ROC-AUC', 'S.D. AUC-ROC', 'Mean Accuracy', 'S.D. Accuracy']\n",
    "df_results = pd.DataFrame(columns=col)\n",
    "auc_results = []\n",
    "acc_results = []\n",
    "i = 0\n",
    "\n",
    "# Fit the models one by one\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=10)  # 5-fold cross-validation\n",
    "    cv_auc_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "    auc_results.append(cv_auc_results)\n",
    "    cv_acc_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_results.append(cv_acc_results)\n",
    "    df_results.loc[i] = [name,\n",
    "                         cv_auc_results.mean(),\n",
    "                         cv_auc_results.std(),\n",
    "                         cv_acc_results.mean(),\n",
    "                         cv_acc_results.std()\n",
    "                         ]\n",
    "    i += 1\n",
    "    print(i)\n",
    "df_results.sort_values(by=['Mean ROC-AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "fig.suptitle('Comparison of ROC-AUC scores for different algorithms')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(auc_results)\n",
    "ax.set_xticklabels(df_results['Algorithm'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So although the classification accuracies for all the models except decision tree are more or less similar, it is not the right indicator because of the class imbalance. Going by the ROC-AUC score, which quantifies a classifier's ability to differentiate between the classes, gradient boosting classifier and logistic regression are better baseline models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search and hyper-parameter tuning <a name=\"grid_search\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression <a name=\"grid_logistic1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(max_iter=1000)\n",
    "C = np.logspace(-2, 4, 10)\n",
    "class_weight = ['None', 'balanced']\n",
    "hyperparameters = dict(C=C, class_weight=class_weight)\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "best_logistic = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1.0\n",
      "Best Class Weight: None\n"
     ]
    }
   ],
   "source": [
    "print('Best Penalty:', best_logistic.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_logistic.best_estimator_.get_params()['C'])\n",
    "print('Best Class Weight:', best_logistic.best_estimator_.get_params()['class_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best case ROC-AUC score for logistic regression model is 0.7805773855640838\n"
     ]
    }
   ],
   "source": [
    "cv_auc_results = cross_val_score(best_logistic.best_estimator_, x_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "print(f'Best case ROC-AUC score for logistic regression model is {cv_auc_results.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost classifier <a name=\"grid_xgboost1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier()\n",
    "learning_rate = [0.05, 0.1, 0.3]\n",
    "n_estimators = [100, 200, 500]\n",
    "max_depth = [3, 6]\n",
    "subsample = [0.5, 0.1]\n",
    "colsample_bytree = [0.5, 1]\n",
    "hyperparameters = dict(learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth, subsample=subsample, colsample_bytree=colsample_bytree)\n",
    "clf = GridSearchCV(xgboost, hyperparameters, cv=5, verbose=0)\n",
    "best_xgboost = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.05\n",
      "Best number of estimators: 500\n",
      "Best maximum depth: 3\n",
      "Best subsample: 0.5\n",
      "Best colsample by tree: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Best learning rate:', best_xgboost.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best number of estimators:', best_xgboost.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best maximum depth:', best_xgboost.best_estimator_.get_params()['max_depth'])\n",
    "print('Best subsample:', best_xgboost.best_estimator_.get_params()['subsample'])\n",
    "print('Best colsample by tree:', best_xgboost.best_estimator_.get_params()['colsample_bytree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best case ROC-AUC score for XGBoost classifier is 0.8008795614223594\n"
     ]
    }
   ],
   "source": [
    "cv_auc_results = cross_val_score(best_xgboost.best_estimator_, x_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "print(f'Best case ROC-AUC score for XGBoost classifier is {cv_auc_results.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection using Recursive Feature Elimination <a name=\"rfe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use RFE to select the top features using random forest classifier and see if using a subset of features can improve classification performance over the baseline for the two most promising candidate algorithms: logistic regression and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'month', 'day_of_week', 'campaign', 'cons.conf.idx', 'euribor3m',\n",
       "       'nr.employed', 'education_university.degree', 'housing_yes',\n",
       "       'poutcome_success'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = RandomForestClassifier(random_state=1)\n",
    "selector = RFE(estimator, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(x_train, y_train)\n",
    "subset_columns = x_train.columns[selector.support_]\n",
    "subset_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>education_university.degree</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.146223</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387151</td>\n",
       "      <td>-0.490205</td>\n",
       "      <td>0.772003</td>\n",
       "      <td>0.865709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.076166</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2.147042</td>\n",
       "      <td>-0.275213</td>\n",
       "      <td>0.716988</td>\n",
       "      <td>0.865709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.146223</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.973782</td>\n",
       "      <td>1.086402</td>\n",
       "      <td>0.774320</td>\n",
       "      <td>0.865709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.511255</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.786110</td>\n",
       "      <td>1.014738</td>\n",
       "      <td>0.714672</td>\n",
       "      <td>0.326483</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017885</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.786110</td>\n",
       "      <td>-1.326284</td>\n",
       "      <td>-1.352159</td>\n",
       "      <td>-1.009227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  month  day_of_week  campaign  cons.conf.idx  euribor3m  \\\n",
       "0 -1.146223      7            5  0.387151      -0.490205   0.772003   \n",
       "1  1.076166      6            3  2.147042      -0.275213   0.716988   \n",
       "2 -1.146223      8            2  0.973782       1.086402   0.774320   \n",
       "3 -0.511255      5            4 -0.786110       1.014738   0.714672   \n",
       "4  0.017885      5            2 -0.786110      -1.326284  -1.352159   \n",
       "\n",
       "   nr.employed  education_university.degree  housing_yes  poutcome_success  \n",
       "0     0.865709                            0            1                 0  \n",
       "1     0.865709                            1            0                 0  \n",
       "2     0.865709                            1            0                 0  \n",
       "3     0.326483                            1            0                 0  \n",
       "4    -1.009227                            0            0                 0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_subset = x_train[subset_columns]\n",
    "x_train_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean ROC-AUC</th>\n",
       "      <th>S.D. AUC-ROC</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>S.D. Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost classifier</td>\n",
       "      <td>0.779204</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>0.005256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.761477</td>\n",
       "      <td>0.011638</td>\n",
       "      <td>0.900395</td>\n",
       "      <td>0.003290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm  Mean ROC-AUC  S.D. AUC-ROC  Mean Accuracy  \\\n",
       "1   XGBoost classifier      0.779204      0.008342       0.896509   \n",
       "0  Logistic regression      0.761477      0.011638       0.900395   \n",
       "\n",
       "   S.D. Accuracy  \n",
       "1       0.005256  \n",
       "0       0.003290  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('Logistic regression', LogisticRegression(max_iter=500)))\n",
    "models.append(('XGBoost classifier', XGBClassifier()))\n",
    "\n",
    "df_subset_results = pd.DataFrame(columns=col)\n",
    "auc_results = []\n",
    "acc_results = []\n",
    "i = 0\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=10)  # 5-fold cross-validation\n",
    "    cv_auc_results = cross_val_score(model, x_train_subset, y_train, cv=kfold, scoring='roc_auc')\n",
    "    auc_results.append(cv_auc_results)\n",
    "    cv_acc_results = cross_val_score(model, x_train_subset, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_results.append(cv_acc_results)\n",
    "    df_subset_results.loc[i] = [name,\n",
    "                         cv_auc_results.mean(),\n",
    "                         cv_auc_results.std(),\n",
    "                         cv_acc_results.mean(),\n",
    "                         cv_acc_results.std()\n",
    "                         ]\n",
    "    i += 1\n",
    "    print(i)\n",
    "df_subset_results.sort_values(by=['Mean ROC-AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the performance of logistic regression deteriorates a little, XGBoost actually performs better with only 10 features. Sweet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search and hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(max_iter=1000)\n",
    "C = np.logspace(-2, 4, 10)\n",
    "class_weight = ['None', 'balanced']\n",
    "hyperparameters = dict(C=C, class_weight=class_weight)\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "best_logistic_subset = clf.fit(x_train_subset, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 4.6415888336127775\n",
      "Best Class Weight: None\n"
     ]
    }
   ],
   "source": [
    "print('Best Penalty:', best_logistic_subset.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_logistic_subset.best_estimator_.get_params()['C'])\n",
    "print('Best Class Weight:', best_logistic_subset.best_estimator_.get_params()['class_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best case ROC-AUC score for logistic regression model with 10 features is 0.7614766433706428\n"
     ]
    }
   ],
   "source": [
    "cv_auc_results = cross_val_score(best_logistic_subset.best_estimator_, x_train_subset, y_train, cv=kfold, scoring='roc_auc')\n",
    "print(f'Best case ROC-AUC score for logistic regression model with 10 features is {cv_auc_results.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier()\n",
    "learning_rate = [0.05, 0.1, 0.3]\n",
    "n_estimators = [100, 200, 500]\n",
    "max_depth = [3, 6]\n",
    "subsample = [0.5, 0.1]\n",
    "colsample_bytree = [0.5, 1]\n",
    "hyperparameters = dict(learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth, subsample=subsample, colsample_bytree=colsample_bytree)\n",
    "clf = GridSearchCV(xgboost, hyperparameters, cv=5, verbose=0)\n",
    "best_xgboost_subset = clf.fit(x_train_subset, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.05\n",
      "Best number of estimators: 200\n",
      "Best maximum depth: 3\n",
      "Best subsample: 0.1\n",
      "Best colsample by tree: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Best learning rate:', best_xgboost_subset.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best number of estimators:', best_xgboost_subset.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best maximum depth:', best_xgboost_subset.best_estimator_.get_params()['max_depth'])\n",
    "print('Best subsample:', best_xgboost_subset.best_estimator_.get_params()['subsample'])\n",
    "print('Best colsample by tree:', best_xgboost_subset.best_estimator_.get_params()['colsample_bytree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best case ROC-AUC score for XGBoost classifier with 10 features is 0.7938766169952183\n"
     ]
    }
   ],
   "source": [
    "cv_auc_results = cross_val_score(best_xgboost_subset.best_estimator_, x_train_subset, y_train, cv=kfold, scoring='roc_auc')\n",
    "print(f'Best case ROC-AUC score for XGBoost classifier with 10 features is {cv_auc_results.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
